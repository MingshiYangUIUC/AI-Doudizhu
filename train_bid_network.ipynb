{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Simple bidding network\n",
    "\n",
    "Train using existing models\n",
    "    1. get random cards\n",
    "    2. for each player, evaluate the win rate assume they get the random public cards and become landlord\n",
    "    3. Supervised learning. X: random cards without public cards, Y: win rate\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import random\n",
    "from collections import Counter\n",
    "from model_utils import *\n",
    "from base_utils import *\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import TensorDataset, DataLoader, ConcatDataset\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_game_3card_nolandlord(): # landlord has 3 more cards, which are visible to all\n",
    "    st = '3333444455556666777788889999XXXXJJJJQQQQKKKKAAAA2222BR'\n",
    "    idx = list(range(54))\n",
    "    random.shuffle(idx)\n",
    "    L = ''.join([st[i] for i in idx[:17]])\n",
    "    B = ''.join([st[i] for i in idx[17:20]]) # the three cards that are visible to all\n",
    "    U = ''.join([st[i] for i in idx[20:37]])\n",
    "    D = ''.join([st[i] for i in idx[37:]])\n",
    "    Lst = str2state_1D(L)\n",
    "    Ust = str2state_1D(U)\n",
    "    Dst = str2state_1D(D)\n",
    "    Bst = str2state_1D(B)\n",
    "    return [Lst,Ust,Dst,Bst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BidModel(nn.Module):\n",
    "    def __init__(self, input_size=15, hidden_size=128, num_hidden_layers=4, output_size=1):\n",
    "        super(BidModel, self).__init__()\n",
    "        \n",
    "        # Define the input layer\n",
    "        self.input_layer = nn.Linear(input_size, hidden_size)\n",
    "        \n",
    "        # Define the hidden layers\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for _ in range(num_hidden_layers - 1):\n",
    "            self.hidden_layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "        \n",
    "        # Define the output layer\n",
    "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Apply the input layer with ReLU activation\n",
    "        x = F.relu(self.input_layer(x))\n",
    "        \n",
    "        # Apply each hidden layer with ReLU activation\n",
    "        for layer in self.hidden_layers:\n",
    "            x = F.relu(layer(x))\n",
    "        \n",
    "        # Apply the output layer\n",
    "        x = torch.sigmoid(self.output_layer(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models\n",
    "\n",
    "name = 'H15-V2_3.0'\n",
    "mfiles = [int(f[-13:-3]) for f in os.listdir(os.path.join('models')) if name + '_' in f]\n",
    "\n",
    "if len(mfiles) == 0:\n",
    "    v_M = f'{name}_{str(0).zfill(10)}'\n",
    "else:\n",
    "    v_M = f'{name}_{str(max(mfiles)).zfill(10)}'\n",
    "\n",
    "SLM = Network_Pcard_V2_2_BN_dropout(15+7, 7, y=1, x=15, lstmsize=256, hiddensize=512)\n",
    "QV = Network_Qv_Universal_V1_2_BN_dropout(11*15,256,512)\n",
    "\n",
    "SLM.load_state_dict(torch.load(os.path.join('models',f'SLM_{v_M}.pt')))\n",
    "QV.load_state_dict(torch.load(os.path.join('models',f'QV_{v_M}.pt')))\n",
    "\n",
    "SLM.eval()\n",
    "QV.eval()\n",
    "\n",
    "\n",
    "\n",
    "print('Model version:', v_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data\n",
    "def generate_dataset(SLM,QV, size=128, device='cpu'):\n",
    "    if device == 'cuda':\n",
    "        dtypem=torch.float16\n",
    "        SLM.to(dtypem).to('cuda')\n",
    "        QV.to(dtypem).to('cuda')\n",
    "    else:\n",
    "        dtypem=torch.float32\n",
    "\n",
    "    simulation_batch_size = size\n",
    "    Init_states = [init_game_3card_nolandlord() for _ in range(simulation_batch_size)]\n",
    "\n",
    "    Cards = torch.stack([torch.stack(ist[:-1],dim=0) for ist in Init_states],dim=0)\n",
    "    Qvalues = torch.zeros((simulation_batch_size,3,1))\n",
    "\n",
    "    for Tidx in (0,1,2): # all players try landlord\n",
    "\n",
    "        model_inputs = []\n",
    "        model_idxs = []\n",
    "        acts_list = []\n",
    "        for iin, _ in enumerate(range(simulation_batch_size)):\n",
    "\n",
    "            #playerstate, model = Init_states[_][Tidx], Models[Tidx] # Same model should be used for all Active\n",
    "            playerstate = Init_states[_][Tidx] + Init_states[_][-1]\n",
    "\n",
    "            #print(Turn)\n",
    "            visible = Init_states[_][-1] # 3 cards from landlord, fixed for one full game\n",
    "\n",
    "            # use unavail_player instead of CC\n",
    "            played_cards = torch.zeros((3,15))\n",
    "\n",
    "            # get actions\n",
    "            acts = avail_actions_cpp('',(0,0),playerstate,True)\n",
    "\n",
    "            # add states and visible to big state\n",
    "            Bigstate = torch.cat([playerstate.unsqueeze(0),\n",
    "                                    #str2state_1D(unavail[_]).unsqueeze(0),\n",
    "                                    torch.zeros(15).unsqueeze(0),\n",
    "                                    #CC,\n",
    "                                    played_cards, # new feature\n",
    "                                    visible.unsqueeze(0), # new feature\n",
    "                                    torch.full((1, 15), 0),\n",
    "                                    torch.zeros((15,15))])\n",
    "            Bigstate = Bigstate.unsqueeze(1) # model is not changed, so unsqueeze here\n",
    "\n",
    "            # generate inputs\n",
    "            model_inputs.append(Bigstate.unsqueeze(0))\n",
    "            model_idxs.append(len(acts))\n",
    "            acts_list.append(acts)\n",
    "\n",
    "        model_inputs = torch.concat(model_inputs)\n",
    "\n",
    "        # predict state (SL)\n",
    "        model_inter, lstm_out = SLM(\n",
    "            model_inputs.to(dtypem).to(device)\n",
    "            )\n",
    "        model_inter = model_inter.to('cpu', torch.float32)\n",
    "        lstm_out = lstm_out.to('cpu', torch.float32)\n",
    "\n",
    "        # use all of model inputs\n",
    "        model_inter = torch.concat([model_inputs[:,0:8,0].view(model_inputs.size(0), -1), # self\n",
    "                                    model_inter, # upper and lower states\n",
    "                                    #role,\n",
    "                                    lstm_out, # lstm encoded history\n",
    "                                    ],dim=-1)\n",
    "        model_input2 = []\n",
    "\n",
    "        for i, mi in enumerate(model_inter):\n",
    "            input_i = torch.stack([torch.cat((mi,str2state_1D(a[0]))) for a in acts_list[i]])\n",
    "            model_input2.append(input_i)\n",
    "\n",
    "        model_output = QV(torch.cat(model_input2).to(dtypem).to(device)).to('cpu').to(torch.float32).flatten()\n",
    "\n",
    "        # evaluate best win rate\n",
    "        for iout, _ in enumerate(range(simulation_batch_size)):\n",
    "\n",
    "            idx_start = sum(model_idxs[:iout])\n",
    "            idx_end = sum(model_idxs[:iout+1])\n",
    "\n",
    "            # get q values\n",
    "            output = model_output[idx_start:idx_end].clone().detach()\n",
    "            q = torch.max(output)\n",
    "            \n",
    "            Qvalues[_,Tidx,0] = q\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return Cards, Qvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(device, model, criterion, loader, nep, optimizer):\n",
    "    #scaler = torch.cuda.amp.GradScaler()\n",
    "    model.to(device)\n",
    "    model.train()  # Set the model to training mode\n",
    "    for epoch in range(nep):\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for inputs, targets in tqdm(loader):\n",
    "            inputs, targets = inputs.to(torch.float32).to(device), targets.to(torch.float32).to(device)\n",
    "            \n",
    "            optimizer.zero_grad()  # Zero the gradients\n",
    "            outputs = model(inputs)  # Forward pass\n",
    "            loss = criterion(outputs, targets)  # Calculate loss\n",
    "            loss.backward()  # Backward pass\n",
    "            optimizer.step()  # Optimize\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Calculate the average loss per batch over the epoch\n",
    "        epoch_loss = running_loss / len(loader)\n",
    "        print(f\"Epoch {epoch+1}/{nep}, Training Loss: {epoch_loss:.4f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''if torch.get_num_threads() > 1:\n",
    "    torch.set_num_threads(1)\n",
    "    torch.set_num_interop_threads(1)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EV = BidModel(input_size=15, hidden_size=128, num_hidden_layers=5, output_size=1)\n",
    "EV.load_state_dict(torch.load(os.path.join('data',f'EV_best.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(200):\n",
    "    print(f'---{i}---              ',end='\\r')\n",
    "    with torch.inference_mode():\n",
    "        Cards, Qvalues = generate_dataset(SLM,QV,2048)\n",
    "    train_loader = DataLoader(TensorDataset(Cards.reshape(-1, 15), Qvalues.reshape(-1, 1)), \n",
    "                            batch_size=512, shuffle=True, num_workers=0, pin_memory=True)\n",
    "    opt = torch.optim.Adam(EV.parameters(), lr=0.00001,weight_decay = 1e-10)\n",
    "    EV = train_model('cuda', EV, torch.nn.MSELoss(), train_loader, 10, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cardstest, Qvaluestest = generate_dataset(SLM,QV,512,'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cardstest.reshape(-1, 15).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EV.eval()\n",
    "EV.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    ypred = EV(Cardstest.reshape(-1, 15))\n",
    "    ytrue = Qvaluestest.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(ypred.numpy(), ytrue.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean((ypred-ytrue)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(EV.state_dict(),os.path.join('data',f'EV_best.pt'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
